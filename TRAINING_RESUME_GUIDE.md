# å­¦ç¿’ã®å†é–‹æ©Ÿèƒ½ã¨å¯è¦–åŒ–ã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ–°æ©Ÿèƒ½

### 1. å„ã‚¨ãƒãƒƒã‚¯ã§å­¦ç¿’æ›²ç·šã®ç”»åƒã‚’è‡ªå‹•ç”Ÿæˆ ğŸ“Š
- Lossæ›²ç·šï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ï¼‰
- Accuracyæ›²ç·šï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ï¼‰
- Learning Rateå¤‰åŒ–

### 2. å­¦ç¿’ã®ä¸­æ–­ãƒ»å†é–‹æ©Ÿèƒ½ ğŸ’¾
- å„ã‚¨ãƒãƒƒã‚¯å¾Œã«è‡ªå‹•çš„ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
- ä¸­æ–­ã—ãŸå ´åˆã§ã‚‚ç¶šãã‹ã‚‰å†é–‹å¯èƒ½
- å­¦ç¿’ç‡ã€optimizerçŠ¶æ…‹ã€å…¨å±¥æ­´ã‚’ä¿å­˜

### 3. è©³ç´°ãªãƒ‡ãƒ¼ã‚¿ä¿å­˜ ğŸ“ˆ
- accuracyï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ï¼‰
- lossï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ï¼‰
- å­¦ç¿’ç‡ã®å±¥æ­´
- ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ä¿å­˜

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªå­¦ç¿’

```bash
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 50
```

### å­¦ç¿’ã‚’ä¸­æ–­ã—ãŸå ´åˆ

å­¦ç¿’ä¸­ã« `Ctrl+C` ã‚’æŠ¼ã™ã¨ã€ä¸­æ–­ã•ã‚Œã¾ã™ã€‚æœ€å¾Œã®ã‚¨ãƒãƒƒã‚¯ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã¯ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚

### å­¦ç¿’ã‚’å†é–‹ã™ã‚‹æ–¹æ³•

#### æ–¹æ³•1: è‡ªå‹•å†é–‹ï¼ˆæ¨å¥¨ï¼‰

```bash
# åŒã˜ã‚³ãƒãƒ³ãƒ‰ã‚’å†å®Ÿè¡Œã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«æ¤œå‡ºã•ã‚Œã¾ã™
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 50

# ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™:
# "å‰å›ã®å­¦ç¿’ã‚’æ¤œå‡ºã—ã¾ã—ãŸ: outputs/demo/checkpoints/latest.pth"
# "å‰å›ã®å­¦ç¿’ã‹ã‚‰å†é–‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): "
# â†’ "y" ã‚’å…¥åŠ›
```

#### æ–¹æ³•2: æ˜ç¤ºçš„ã«æŒ‡å®š

```bash
# ç‰¹å®šã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 50 \
    --resume outputs/demo/checkpoints/latest.pth
```

#### æ–¹æ³•3: ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å†é–‹

```bash
# æœ€è‰¯ã®ç²¾åº¦ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å†é–‹
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 100 \
    --resume outputs/demo/checkpoints/best_acc.pth
```

---

## ğŸ“ ä¿å­˜ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

```
outputs/demo/checkpoints/
â”œâ”€â”€ latest.pth                    # æœ€æ–°ã®ã‚¨ãƒãƒƒã‚¯ï¼ˆå†é–‹ç”¨ï¼‰
â”œâ”€â”€ best_acc.pth                  # æœ€é«˜ç²¾åº¦ã®ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ best_loss.pth                 # æœ€å°lossã®ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ checkpoint_epoch_10.pth       # 10ã‚¨ãƒãƒƒã‚¯ã”ã¨
â”œâ”€â”€ checkpoint_epoch_20.pth
â””â”€â”€ ...
```

**å„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã«å«ã¾ã‚Œã‚‹æƒ…å ±:**
- ã‚¨ãƒãƒƒã‚¯ç•ªå·
- ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿
- optimizerã®çŠ¶æ…‹
- schedulerã®çŠ¶æ…‹
- è¨“ç·´å±¥æ­´ï¼ˆlossã€accuracyï¼‰
- æ¤œè¨¼å±¥æ­´ï¼ˆlossã€accuracyï¼‰
- å­¦ç¿’ç‡å±¥æ­´
- æœ€è‰¯ã‚¹ã‚³ã‚¢ï¼ˆbest_val_accã€best_val_lossï¼‰

### å­¦ç¿’æ›²ç·šã®ç”»åƒ

```
outputs/demo/logs/plots/
â”œâ”€â”€ training_curves_latest.png        # æœ€æ–°ã®æ›²ç·š
â”œâ”€â”€ training_curves_epoch_0001.png    # ã‚¨ãƒãƒƒã‚¯1
â”œâ”€â”€ training_curves_epoch_0002.png    # ã‚¨ãƒãƒƒã‚¯2
â””â”€â”€ ...
```

**ç”»åƒã®å†…å®¹:**
- å·¦: Lossæ›²ç·šï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ï¼‰
- ä¸­å¤®: Accuracyæ›²ç·šï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ï¼‰
- å³: Learning Rateå¤‰åŒ–

### å­¦ç¿’å±¥æ­´JSON

```
outputs/demo/logs/training_history.json
```

**å†…å®¹:**
```json
{
  "train": [
    {"loss": 2.5, "accuracy": 0.35},
    {"loss": 2.3, "accuracy": 0.38},
    ...
  ],
  "val": [
    {"loss": 2.6, "accuracy": 0.34},
    {"loss": 2.4, "accuracy": 0.36},
    ...
  ],
  "learning_rate": [0.0001, 0.0001, ...],
  "best_val_acc": 0.42,
  "best_val_loss": 2.1
}
```

---

## ğŸ’¡ å®Ÿè¡Œä¾‹

### ä¾‹1: é€šå¸¸ã®å­¦ç¿’ï¼ˆ50ã‚¨ãƒãƒƒã‚¯ï¼‰

```bash
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 50 \
    --batch-size 256 \
    --learning-rate 1e-4
```

**å‡ºåŠ›:**
- å„ã‚¨ãƒãƒƒã‚¯çµ‚äº†æ™‚ã«ç”»åƒã‚’ç”Ÿæˆ
- 10ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜
- ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ä¿å­˜

### ä¾‹2: å­¦ç¿’ãŒä¸­æ–­ã•ã‚ŒãŸå ´åˆ

```bash
# ã‚¨ãƒãƒƒã‚¯25ã§ä¸­æ–­ï¼ˆCtrl+Cï¼‰
# ... å‡¦ç†ä¸­ ...
# ^C
# âš ï¸  å­¦ç¿’ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ

# å†é–‹
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 50

# å‡ºåŠ›ä¾‹:
# "å‰å›ã®å­¦ç¿’ã‚’æ¤œå‡ºã—ã¾ã—ãŸ: outputs/demo/checkpoints/latest.pth"
# "å‰å›ã®å­¦ç¿’ã‹ã‚‰å†é–‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): y"
# "âœ… Loaded checkpoint from epoch 25"
# "   Best val acc: 0.3850"
# "   Best val loss: 2.2500"
# "   Resuming from epoch 26"
```

### ä¾‹3: ã•ã‚‰ã«é•·ãå­¦ç¿’

```bash
# 50ã‚¨ãƒãƒƒã‚¯å®Œäº†å¾Œã€ã•ã‚‰ã«50ã‚¨ãƒãƒƒã‚¯è¿½åŠ 

python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 100 \
    --resume outputs/demo/checkpoints/latest.pth
```

### ä¾‹4: å­¦ç¿’ç‡ã‚’å¤‰æ›´ã—ã¦å†é–‹

```bash
# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã€å­¦ç¿’ç‡ã‚’ä¸‹ã’ã¦å†é–‹
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo_finetune \
    --epochs 80 \
    --resume outputs/demo/checkpoints/best_acc.pth \
    --learning-rate 5e-5
```

---

## ğŸ“Š å­¦ç¿’æ›²ç·šã®ç¢ºèª

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç¢ºèª

```bash
# åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§
watch -n 5 "ls -lh outputs/demo/logs/plots/training_curves_latest.png"

# ã¾ãŸã¯ç”»åƒãƒ“ãƒ¥ãƒ¼ã‚¢ã§é–‹ã
eog outputs/demo/logs/plots/training_curves_latest.png
# ã¾ãŸã¯
xdg-open outputs/demo/logs/plots/training_curves_latest.png
```

### å±¥æ­´JSONã‚’ç¢ºèª

```bash
# æœ€æ–°ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º
python -c "
import json
with open('outputs/demo/logs/training_history.json', 'r') as f:
    history = json.load(f)
    print(f'ã‚¨ãƒãƒƒã‚¯æ•°: {len(history[\"train\"])}')
    print(f'æœ€æ–°Train Acc: {history[\"train\"][-1][\"accuracy\"]:.4f}')
    print(f'æœ€æ–°Val Acc: {history[\"val\"][-1][\"accuracy\"]:.4f}')
    print(f'ãƒ™ã‚¹ãƒˆVal Acc: {history[\"best_val_acc\"]:.4f}')
    print(f'ãƒ™ã‚¹ãƒˆVal Loss: {history[\"best_val_loss\"]:.4f}')
"
```

---

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q1: ç”»åƒãŒç”Ÿæˆã•ã‚Œãªã„

**A:** matplotlibãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª:
```bash
pip install matplotlib
```

### Q2: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ã§ããªã„

**A:** ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª:
```bash
ls -lh outputs/demo/checkpoints/
```

ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèª:
```bash
cat outputs/demo/train.log | tail -20
```

### Q3: å­¦ç¿’æ›²ç·šãŒè¡¨ç¤ºã•ã‚Œãªã„ç’°å¢ƒ

**A:** Non-interactiveãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ã€‚
```bash
# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
ls outputs/demo/logs/plots/

# åˆ¥ã®ãƒã‚·ãƒ³ã«ã‚³ãƒ”ãƒ¼ã—ã¦è¡¨ç¤º
scp user@server:outputs/demo/logs/plots/training_curves_latest.png ./
```

### Q4: ãƒ¡ãƒ¢ãƒªä¸è¶³ã§ä¸­æ–­ã•ã‚ŒãŸ

**A:** ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã—ã¦å†é–‹:
```bash
python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 50 \
    --resume outputs/demo/checkpoints/latest.pth \
    --batch-size 128
```

---

## ğŸ“ˆ å­¦ç¿’ã®é€²æ—ç¢ºèª

### ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç›£è¦–

```bash
# åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§
tail -f outputs/demo/train.log

# ã¾ãŸã¯ã€ã‚¨ãƒãƒƒã‚¯æƒ…å ±ã ã‘ã‚’æŠ½å‡º
tail -f outputs/demo/train.log | grep "Epoch"
```

### ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª

```bash
python -c "
import torch
checkpoint = torch.load('outputs/demo/checkpoints/latest.pth', map_location='cpu')
print(f'ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯: {checkpoint[\"epoch\"]}')
print(f'ãƒ™ã‚¹ãƒˆVal Acc: {checkpoint[\"best_val_acc\"]:.4f}')
print(f'ãƒ™ã‚¹ãƒˆVal Loss: {checkpoint[\"best_val_loss\"]:.4f}')
print(f'ç·ã‚¨ãƒãƒƒã‚¯æ•°: {len(checkpoint[\"train_history\"])}')
"
```

---

## ğŸ¯ ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. å®šæœŸçš„ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜

```bash
# 5ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ä¿å­˜
python scripts/train_demo.py \
    --save-every 5 \
    --epochs 50
```

### 2. è¤‡æ•°ã®å®Ÿé¨“ã‚’ä¸¦è¡Œå®Ÿè¡Œ

```bash
# å®Ÿé¨“1: æ¨™æº–è¨­å®š
python scripts/train_demo.py \
    --output-dir outputs/exp1_standard

# å®Ÿé¨“2: å¤§ãã„ãƒ¢ãƒ‡ãƒ«
python scripts/train_demo.py \
    --output-dir outputs/exp2_large \
    --d-model 512 \
    --num-layers 8

# å®Ÿé¨“3: ä½å­¦ç¿’ç‡
python scripts/train_demo.py \
    --output-dir outputs/exp3_lowlr \
    --learning-rate 5e-5
```

### 3. é•·æ™‚é–“å­¦ç¿’ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ

```bash
# nohupã§å®Ÿè¡Œ
nohup python scripts/train_demo.py \
    --data-dir data/processed_demo \
    --output-dir outputs/demo \
    --epochs 100 \
    > train.out 2>&1 &

# ãƒ—ãƒ­ã‚»ã‚¹IDã‚’ç¢ºèª
echo $!

# ãƒ­ã‚°ã‚’ç›£è¦–
tail -f train.out
```

### 4. GPUä½¿ç”¨ç‡ã®ç›£è¦–

```bash
# åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§
watch -n 1 nvidia-smi
```

---

## ğŸ“ ã¾ã¨ã‚

### æ–°æ©Ÿèƒ½ã®ãƒ¡ãƒªãƒƒãƒˆ

âœ… **å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–**
- å„ã‚¨ãƒãƒƒã‚¯ã§è‡ªå‹•çš„ã«ç”»åƒç”Ÿæˆ
- å­¦ç¿’ã®é€²æ—ã‚’è¦–è¦šçš„ã«ç¢ºèªå¯èƒ½

âœ… **å­¦ç¿’ã®å†é–‹æ©Ÿèƒ½**
- ä¸­æ–­ã—ã¦ã‚‚ç¶šãã‹ã‚‰å†é–‹
- å­¦ç¿’ç‡ã€optimizerçŠ¶æ…‹ã‚’å®Œå…¨ã«å¾©å…ƒ

âœ… **ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ä¿å­˜**
- accuracyã€lossã€å­¦ç¿’ç‡ã®å…¨å±¥æ­´
- ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ä¿å­˜

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```bash
# 1. å­¦ç¿’é–‹å§‹
python scripts/train_demo.py --data-dir data/processed_demo --epochs 50

# 2. ä¸­æ–­ã•ã‚ŒãŸå ´åˆï¼ˆCtrl+Cï¼‰

# 3. å†é–‹ï¼ˆè‡ªå‹•æ¤œå‡ºï¼‰
python scripts/train_demo.py --data-dir data/processed_demo --epochs 50
# â†’ "y" ã‚’å…¥åŠ›

# 4. å­¦ç¿’æ›²ç·šã‚’ç¢ºèª
xdg-open outputs/demo/logs/plots/training_curves_latest.png
```

---

**Happy Training! ğŸš€ğŸ€„**

