# 天鳳麻雀データ変換パイプライン設計書

## 1. 概要

本文書は、天鳳の約20万試合のXMLログから、教師あり学習モデル用の固定長ベクトル化データへの変換パイプラインを定義します。

## 2. データフロー

```
XMLログ → 解析 → ゲーム状態抽出 → 特徴量エンコーディング → 固定長ベクトル化 → NumPy配列保存
   ↓         ↓           ↓                  ↓                    ↓
検証      検証      検証              検証                 データ分割
```

### 2.1 処理ステップ

1. **XML解析（Enhanced XML Parser）**
   - 入力：天鳳XML形式のゲームログ
   - 出力：構造化されたGameオブジェクト
   - 機能：
     - 手出し/ツモ切り区別
     - 赤ドラ（5m/5s/5p）検出
     - リーチ宣言巡目の追跡
     - ドラ表示牌の管理

2. **ゲーム状態追跡（Comprehensive Game State Tracker）**
   - 入力：Gameオブジェクト
   - 出力：各打牌タイミングでの完全なゲーム状態
   - 機能：
     - 手牌の再構成（13/14枚）
     - ツモ履歴の記録
     - 河（捨て牌）履歴の管理
     - 鳴き履歴の追跡
     - リーチ状態の管理
     - 点数変動の追跡
     - 待ち牌・テンパイ状態の計算

3. **特徴量エンコーディング（Advanced Feature Encoder）**
   - 入力：ゲーム状態
   - 出力：固定長特徴ベクトル
   - 特徴量構成：以下を参照

4. **データセット構築（Dataset Builder with Validation）**
   - 入力：特徴ベクトルとラベル
   - 出力：train/val/test分割されたNumPy配列
   - 機能：
     - データ整合性検証
     - 固定シード分割（80%/10%/10%）
     - データリーク防止

## 3. 特徴量ベクトル構成

各サンプルは1つの「打牌タイミング」を表し、以下の固定長ベクトルで構成されます。

### 3.1 基本特徴量（1x34エンコーディング）

| カテゴリ | 次元数 | 説明 |
|---------|--------|------|
| 自分の手牌 | 34 | 各牌種の枚数（0-4） |
| 自分の副露 | 34 | 鳴いた牌の枚数 |
| 自分の捨て牌 | 34 | 自分の河の牌枚数 |
| 対家1の捨て牌 | 34 | 下家の河 |
| 対家2の捨て牌 | 34 | 対面の河 |
| 対家3の捨て牌 | 34 | 上家の河 |
| 対家1の副露 | 34 | 下家の鳴き |
| 対家2の副露 | 34 | 対面の鳴き |
| 対家3の副露 | 34 | 上家の鳴き |
| ドラ表示牌 | 34 | ドラ表示牌（複数ドラ対応） |
| **小計** | **340** | **1x34 × 10グループ** |

### 3.2 時系列特徴量

| カテゴリ | 次元数 | 説明 |
|---------|--------|------|
| ツモ履歴（直近k手） | k × 34 | 直近k回のツモ牌（one-hot） |
| 全体捨て牌履歴（直近m手） | m × 39 | 牌34次元 + プレイヤー4次元 + リーチフラグ1次元 |
| **小計** | **k×34 + m×39** | **例: k=8, m=32の場合 1,520次元** |

### 3.3 メタ特徴量

| カテゴリ | 次元数 | 説明 |
|---------|--------|------|
| 局情報 | 8 | 東/南、局数、本場数、供託棒数 |
| 親子情報 | 4 | 各プレイヤーの親フラグ（one-hot） |
| リーチ宣言 | 4 | 各プレイヤーのリーチ状態 |
| リーチ巡目 | 4 | リーチ宣言した巡目（正規化） |
| 点数状態 | 4 | 各プレイヤーの点数（正規化, /100000） |
| 点数差 | 1 | 自分と1位の点差（正規化） |
| 順位 | 1 | 現在の順位（1-4） |
| ターン情報 | 2 | 現在の巡目、残りツモ数（正規化） |
| 赤ドラ情報 | 3 | 見えている赤5m/5s/5pの枚数 |
| **小計** | **31** | |

### 3.4 待ち・向聴数特徴量

| カテゴリ | 次元数 | 説明 |
|---------|--------|------|
| 向聴数 | 1 | シャンテン数（-1=和了, 0=テンパイ） |
| テンパイフラグ | 1 | 0/1フラグ |
| 待ち枚数 | 1 | 待ち牌の総枚数 |
| 待ち種類数 | 1 | 何種類の牌で待っているか |
| 待ち牌 | 34 | 待ち牌のone-hot（複数可） |
| **小計** | **38** | |

### 3.5 捨て牌メタ情報

| カテゴリ | 次元数 | 説明 |
|---------|--------|------|
| 手出し/ツモ切りフラグ | 4 × 34 | 各プレイヤーの各牌種で手出しorツモ切り比率 |
| 危険度推定 | 34 | 各牌の危険度スコア（リーチ者の情報から） |
| **小計** | **170** | |

### 3.6 総次元数

```
基本特徴量:        340
時系列特徴量:      1,520  (k=8, m=32の場合)
メタ特徴量:        31
待ち・向聴数:      38
捨て牌メタ情報:    170
━━━━━━━━━━━━━━━━━━━━━━━━
合計:            2,099 次元
```

**調整可能パラメータ:**
- `k` (ツモ履歴長): 推奨 4-16
- `m` (捨て牌履歴長): 推奨 16-64
- GPUメモリ制約に応じて調整可能

## 4. ラベル定義

### 4.1 打牌ラベル（基本）

- **形式**: One-hot 34次元
- **値**: 実際に打牌した牌種（0-33）
- **例**: 5m を打牌 → インデックス4が1、他は0

### 4.2 拡張ラベル（オプション）

複数タスクで学習する場合：

| タスク | 次元数 | 説明 |
|--------|--------|------|
| 打牌選択 | 34 | どの牌を切るか |
| 鳴き判断 | 4 | なし/チー/ポン/カン |
| リーチ判断 | 2 | リーチする/しない |
| **合計** | **40** | マルチタスク学習用 |

本実装では**打牌選択（34次元）のみ**を使用します。

## 5. データ分割戦略

### 5.1 分割比率

```python
train_ratio = 0.80  # 訓練データ
val_ratio   = 0.10  # 検証データ
test_ratio  = 0.10  # テストデータ
```

### 5.2 分割方法

**ゲーム単位での分割（データリーク防止）**

```
全ゲーム → シャッフル（固定seed=42） → ゲーム単位で分割
```

同じゲーム内の打牌が異なるセット間に入らないようにする。

### 5.3 ファイル出力

```
data/processed/
├── train/
│   ├── X_train.npy          # 特徴量 [N_train, D]
│   ├── y_train.npy          # ラベル [N_train]
│   └── metadata_train.json  # ゲームID、局番号など
├── val/
│   ├── X_val.npy
│   ├── y_val.npy
│   └── metadata_val.json
├── test/
│   ├── X_test.npy
│   ├── y_test.npy
│   └── metadata_test.json
└── dataset_info.json        # データセット全体の統計情報
```

## 6. データ検証

各ステップで以下を検証：

### 6.1 XML解析時

- [x] XML構文の正当性
- [x] 必須タグの存在確認
- [x] 牌IDの範囲チェック（0-135）
- [x] プレイヤー数の確認（4人）

### 6.2 ゲーム状態構築時

- [x] 手牌枚数の整合性（13/14枚）
- [x] 各牌種が4枚を超えないこと
- [x] 全体で136枚を超えないこと
- [x] 副露と手牌の整合性

### 6.3 特徴量エンコーディング時

- [x] 特徴量ベクトルの次元数チェック
- [x] NaN/Inf値の検出
- [x] ラベルの範囲チェック（0-33）
- [x] 正規化範囲の確認（0-1）

### 6.4 データセット構築時

- [x] サンプル数の一致
- [x] データリークの確認（ゲームIDの重複チェック）
- [x] 分割比率の検証
- [x] クラスバランスの確認

## 7. モジュール構成

### 7.1 ファイル構造

```
src/preprocessing/
├── __init__.py
├── parse_xml.py               # 既存（拡張）
├── enhanced_parser.py         # NEW: 拡張XML解析
├── game_state_tracker.py      # NEW: 包括的状態追跡
├── feature_encoder_v2.py      # NEW: 高度な特徴量エンコーディング
├── feature_encoder.py         # 既存（互換性維持）
├── dataset_builder_v2.py      # NEW: 完全なデータセット構築
├── dataset_builder.py         # 既存（互換性維持）
├── data_validator.py          # NEW: データ検証
└── advanced_game_state.py     # 既存（部分利用）
```

### 7.2 主要クラス

#### EnhancedXMLParser
- XML解析の拡張版
- 手出し/ツモ切り検出
- 赤ドラ検出
- タイムスタンプ管理

#### ComprehensiveGameStateTracker
- 全情報を保持するゲーム状態管理
- ツモ履歴、河履歴、副露履歴
- リーチ状態、点数管理
- 待ち・向聴数計算インターフェース

#### AdvancedFeatureEncoderV2
- 2,099次元（可変）の特徴ベクトル生成
- 時系列特徴の管理
- メタ特徴の計算
- 正規化処理

#### ComprehensiveDatasetBuilder
- ゲーム単位での分割
- データ検証の統合
- メタデータの保存
- 統計情報の出力

#### DataValidator
- 各ステップでの検証
- エラーレポート生成
- 整合性チェック

## 8. 使用方法

### 8.1 基本的な使用例

```python
from src.preprocessing import (
    ComprehensiveDatasetBuilder,
    DataValidator
)

# データセットビルダーの初期化
builder = ComprehensiveDatasetBuilder(
    xml_dir='data/xml_logs',
    output_dir='data/processed',
    config={
        'draw_history_length': 8,      # ツモ履歴の長さ
        'discard_history_length': 32,  # 捨て牌履歴の長さ
        'enable_shanten_calc': True,   # 向聴数計算を有効化
        'enable_danger_estimation': True,  # 危険度推定を有効化
        'random_seed': 42,
    }
)

# データセット構築
stats = builder.build_complete_dataset(
    max_games=200000,
    validate=True,  # 検証を有効化
    show_progress=True
)

# データ分割
builder.split_dataset(
    train_ratio=0.80,
    val_ratio=0.10,
    test_ratio=0.10
)

# 統計情報の表示
print(f"総サンプル数: {stats['total_samples']}")
print(f"総ゲーム数: {stats['total_games']}")
print(f"特徴量次元数: {stats['feature_dim']}")
print(f"データ検証: {'合格' if stats['validation_passed'] else '不合格'}")
```

### 8.2 学習用データローダーの作成

```python
import numpy as np
import torch
from torch.utils.data import TensorDataset, DataLoader

# データ読み込み
X_train = np.load('data/processed/train/X_train.npy')
y_train = np.load('data/processed/train/y_train.npy')

# PyTorch Dataset作成
train_dataset = TensorDataset(
    torch.from_numpy(X_train),
    torch.from_numpy(y_train)
)

# DataLoader作成
train_loader = DataLoader(
    train_dataset,
    batch_size=256,
    shuffle=True,
    num_workers=4,
    pin_memory=True
)
```

## 9. パフォーマンス考慮事項

### 9.1 メモリ使用量

20万ゲーム（約1,000万サンプル）の場合：

```
特徴量: 10,000,000 × 2,099 × 4 bytes = 約80 GB
ラベル: 10,000,000 × 8 bytes = 約76 MB
合計: 約80 GB
```

**対策:**
- チャンクごとに処理（10,000ゲームずつ）
- メモリマップド配列の使用（`np.memmap`）
- float16の使用（精度が許容される場合）

### 9.2 処理時間

推定処理時間（8コアCPU）：

- XML解析: 1ゲーム/秒 → 約55時間
- 特徴量抽出: 0.5ゲーム/秒 → 約111時間
- 合計: 約166時間（約7日間）

**高速化:**
- マルチプロセス並列化（8プロセス → 約21時間）
- GPUでの向聴数計算（可能な場合）
- キャッシュ機構（既処理ゲームのスキップ）

### 9.3 ディスク使用量

```
data/
├── xml_logs/          ~10 GB（圧縮XML）
├── processed/         ~85 GB（NumPy配列）
└── cache/             ~20 GB（中間データ）
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
合計:                  ~115 GB
```

## 10. エラーハンドリング

### 10.1 エラーログ

```
logs/
├── parsing_errors.log      # XML解析エラー
├── validation_errors.log   # データ検証エラー
├── conversion_errors.log   # 変換エラー
└── summary.log             # 全体サマリー
```

### 10.2 リカバリー機構

- チェックポイント保存（1,000ゲームごと）
- 失敗したゲームのスキップ
- エラーゲームリストの保存
- 再実行時の自動スキップ

## 11. 今後の拡張

### 11.1 追加特徴量候補

- [ ] 和了確率の事前計算
- [ ] ヒートマップ特徴（盤面の2D表現）
- [ ] プレイヤー傾向（過去の統計）
- [ ] 流局までの残りターン予測

### 11.2 最適化

- [ ] C++での向聴数計算
- [ ] CUDA実装（可能な部分）
- [ ] データ圧縮（量子化）
- [ ] オンザフライ特徴量生成

## 12. 参考文献

- 天鳳ログフォーマット: https://gimite.net/pukiwiki/index.php?Tenhou%20Log%20Format
- Mahjong AI研究: Tjong et al. "Deep Learning for Mahjong AI"
- Transformer-in-Transformer: Yuan et al. "Tokens-to-Token ViT"

---

**バージョン:** 1.0  
**最終更新:** 2025-10-26  
**作成者:** Mahjong AI Team

