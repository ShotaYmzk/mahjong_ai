# Training Configuration for Mahjong AI - Supervised Learning Only

# Data settings
data:
  data_dir: "data/raw"
  processed_dir: "data/processed"
  split_dir: "data/split"
  batch_size: 512  # VRAM 12GB想定
  num_workers: 4
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  max_games: null  # null for all games, or specify a number
  
  # 打牌履歴を含む特徴量
  use_discard_history: true  # 全員の打牌履歴を使用
  max_discard_history: 64  # 最大保持する打牌数

# Model settings (refer to model_config.yaml for model architecture)
model_type: "tit"  # Options: "tit", "simplified_transformer"
load_checkpoint: null  # Path to checkpoint to resume from

# Training hyperparameters - Supervised Learning
# Target: ~15M parameters, 100-150 epochs
training:
  num_epochs: 150
  learning_rate: 0.0001  # 1e-4
  weight_decay: 0.01
  optimizer: "adamw"  # AdamW optimizer
  scheduler: "cosine"  # Cosine annealing decay
  scheduler_params:
    T_max: 150  # For cosine scheduler (match num_epochs)
    eta_min: 1e-6  # Minimum learning rate
  
  # Gradient clipping
  max_grad_norm: 1.0
  
  # Early stopping
  early_stopping: true
  early_stopping_patience: 20  # Increased for 150 epochs

# Loss function - Supervised Learning
loss:
  type: "cross_entropy"
  label_smoothing: 0.0  # Label smoothingを使用する場合は0.1など
  
  # クラス不均衡への対応
  use_class_weights: false  # クラスウェイトを使用するか
  
# Regularization
regularization:
  dropout: 0.1
  weight_decay: 0.01

# Logging and checkpointing
logging:
  log_interval: 100  # Log every N batches
  log_dir: "outputs/logs"
  checkpoint_dir: "outputs/checkpoints"
  save_every_n_epochs: 10
  save_best_only: false  # Also save periodic checkpoints

# Visualization
visualization:
  plot_dir: "outputs/visualizations"
  plot_attention: true
  plot_metrics: true

# Random seed for reproducibility
seed: 42

# Device settings
device:
  use_cuda: true
  device_id: 0

# Mixed precision training (for faster training)
mixed_precision: false

# Data augmentation (optional)
augmentation:
  enabled: false
  rotation: false  # 手牌のローテーション
  
# Evaluation during training
evaluation:
  compute_shanten: true  # シャンテン数も評価に含める
  top_k_accuracies: [1, 3, 5]  # 計算するTop-K精度

